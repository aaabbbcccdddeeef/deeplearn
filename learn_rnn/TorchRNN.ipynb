{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "输入数据 tensor([[[-0.0094,  0.1015,  0.5219,  1.3011, -0.5181, -0.0673, -0.3861,\n           0.3920, -1.4652,  0.0862],\n         [-0.7655, -0.6013,  0.1323, -0.0936,  0.7161,  0.0727, -1.6502,\n           0.0453, -0.3107,  0.6832],\n         [-0.3019,  1.2306, -0.4231, -0.2478,  0.7904, -0.3890, -0.0494,\n          -1.1294, -1.7622,  0.0880]],\n\n        [[ 2.0557, -0.9231,  0.1915, -0.1496,  1.9265,  0.3803,  0.5163,\n          -0.3818,  0.3600,  2.7738],\n         [ 0.1043, -0.0852,  0.9532, -2.2239, -1.3257, -0.4184,  0.9553,\n           1.1042, -1.1062,  0.0086],\n         [ 0.4098, -0.2268, -1.3558,  0.9900, -0.1862,  1.2226, -0.3115,\n           0.1589,  0.0615,  0.2103]],\n\n        [[-2.2260, -0.3388, -0.8837,  1.2457,  0.8364,  1.9416, -0.6722,\n           0.4724, -0.1019,  0.4015],\n         [ 0.4684, -0.1883,  0.1056,  2.1078, -0.3747,  0.8143,  1.5337,\n          -1.0811,  0.7241,  1.6384],\n         [-0.9574,  2.6561,  1.2859, -1.0305,  0.3230, -0.5593,  1.2155,\n           1.0698, -0.7731,  0.6261]],\n\n        [[-1.2410, -1.1829,  0.2950,  0.3294, -0.0104, -1.1821,  1.1729,\n          -1.4581,  1.6739,  2.0020],\n         [ 1.4694, -0.4045,  1.8229,  0.0903, -1.2734, -0.9698, -0.6408,\n          -1.1809,  1.5610, -0.7515],\n         [ 1.6332,  0.1496,  0.1852,  1.9695,  0.0809,  0.8611, -1.2557,\n           0.1979, -0.6182, -0.1136]],\n\n        [[ 1.2817, -0.1175, -0.7152, -1.0804,  0.2634, -1.6068, -0.4356,\n           1.0395,  0.2456, -0.7535],\n         [ 0.7975,  0.1484, -0.2637,  0.6638,  0.3236,  0.5491, -0.2296,\n           2.0425,  0.3104, -0.4747],\n         [-0.2645,  0.5802,  0.7770, -1.8925, -0.0600,  0.5183, -1.7218,\n           1.4938, -0.0956, -0.2958]]])\n最后一个隐藏层 torch.Size([1, 3, 20])\n输出所有隐藏层 torch.Size([5, 3, 20])\nweight_ih_l0 tensor([[ 0.2210, -0.1218,  0.0093,  0.1438, -0.0670, -0.0668, -0.0330, -0.1018,\n         -0.1240,  0.0114],\n        [-0.0533,  0.0195, -0.1924,  0.2072, -0.0132, -0.1351, -0.1212, -0.1805,\n         -0.0560, -0.0431],\n        [ 0.1476, -0.0153, -0.0033, -0.1632,  0.0674, -0.1462, -0.2095, -0.2044,\n         -0.0469, -0.1206],\n        [-0.1599, -0.0297, -0.1974, -0.1893,  0.2076, -0.0019, -0.1089,  0.1617,\n          0.1553,  0.0137],\n        [ 0.1950, -0.2049,  0.0977,  0.0271, -0.0569,  0.0020,  0.1511, -0.2007,\n         -0.1376,  0.1682],\n        [-0.1346,  0.1058,  0.1930, -0.1770,  0.0863,  0.1029,  0.0416, -0.1321,\n          0.1959, -0.1226],\n        [-0.1554,  0.1290, -0.1968, -0.1346,  0.0448,  0.1194,  0.1003, -0.1098,\n          0.1617, -0.0099],\n        [-0.1660,  0.1962,  0.1056, -0.0896, -0.0243, -0.1019,  0.0532, -0.0706,\n         -0.1310, -0.1583],\n        [ 0.0867, -0.0777,  0.1377, -0.2223,  0.1254,  0.0308, -0.1121, -0.1304,\n         -0.0925,  0.0971],\n        [-0.0283,  0.0787,  0.0093, -0.1820,  0.2200, -0.0363, -0.0617, -0.1140,\n         -0.0928,  0.1221],\n        [-0.0228, -0.1684, -0.0616,  0.2043, -0.0910,  0.0553,  0.0458,  0.0567,\n         -0.0722,  0.1790],\n        [ 0.1949, -0.1598, -0.0748,  0.1736,  0.0164, -0.0614,  0.0841,  0.1607,\n          0.0512, -0.2186],\n        [-0.2000, -0.1104,  0.0754,  0.1508, -0.0905, -0.1568,  0.0979,  0.1811,\n         -0.1691, -0.1413],\n        [ 0.0140, -0.1338, -0.0272, -0.2037,  0.0192,  0.1907, -0.1305,  0.0213,\n          0.0043, -0.1639],\n        [-0.0987,  0.0153, -0.1213, -0.0082, -0.1514,  0.1171, -0.1706,  0.1955,\n         -0.1143, -0.0080],\n        [-0.0491, -0.0845,  0.1474,  0.0611,  0.1041,  0.2200,  0.2019, -0.0922,\n         -0.1109,  0.1608],\n        [ 0.1175, -0.0448, -0.0548,  0.2081, -0.0188, -0.2045, -0.0170,  0.1483,\n         -0.1438,  0.0283],\n        [ 0.1576,  0.1625, -0.1900, -0.0900,  0.0293,  0.0888, -0.0999,  0.1800,\n         -0.0075, -0.0154],\n        [-0.2094, -0.1614, -0.1506, -0.0927, -0.0114, -0.1092, -0.0698,  0.1959,\n          0.1485,  0.1132],\n        [-0.1089, -0.0853,  0.2108,  0.0829, -0.1367,  0.1362, -0.1636,  0.1395,\n          0.0541, -0.1685]])\nweight_hh_l0 tensor([[ 0.1988,  0.2135, -0.0095, -0.2086,  0.0021,  0.1794, -0.2233,  0.1368,\n          0.0057,  0.0248, -0.0458, -0.0586, -0.1694, -0.2099,  0.2061, -0.0551,\n          0.1122,  0.2208, -0.0881, -0.2196],\n        [ 0.0336,  0.1399,  0.2130, -0.1800,  0.0662,  0.0060, -0.0051,  0.0848,\n         -0.1149,  0.1540, -0.0747, -0.0783,  0.1927,  0.0812, -0.2000,  0.1134,\n          0.1715, -0.0512, -0.1022, -0.0900],\n        [-0.1626,  0.0829, -0.1130, -0.2061,  0.0742, -0.1018,  0.1816,  0.1680,\n         -0.0738, -0.0936, -0.1180,  0.0968,  0.1678,  0.0906,  0.2109, -0.0366,\n         -0.1164,  0.1300, -0.0553, -0.0630],\n        [-0.1907, -0.1608,  0.2222,  0.1263,  0.1026,  0.1474,  0.1560, -0.0871,\n          0.1682, -0.1988, -0.0066, -0.0999,  0.0070, -0.0648,  0.0588,  0.1889,\n          0.0901, -0.2162, -0.0893,  0.0351],\n        [ 0.0808,  0.1908, -0.0783, -0.1707,  0.0931, -0.0620, -0.1505,  0.1043,\n          0.0329,  0.0566, -0.0277, -0.1710,  0.2201, -0.0370, -0.0333, -0.1599,\n         -0.1191,  0.0375, -0.1879, -0.0624],\n        [ 0.1974, -0.2165, -0.1457, -0.0506,  0.0526, -0.2212, -0.0288,  0.1893,\n         -0.0071,  0.0136, -0.0428, -0.2192, -0.0248,  0.0649,  0.0615, -0.2133,\n          0.2081,  0.0563,  0.0972,  0.2018],\n        [-0.0921, -0.2138, -0.2043,  0.2199,  0.1090, -0.0068,  0.0609, -0.1403,\n          0.1192,  0.0464,  0.1951, -0.0379, -0.1308, -0.1691,  0.1533, -0.0394,\n          0.1502,  0.0948, -0.0766, -0.0403],\n        [ 0.2011, -0.1924,  0.0202, -0.1488, -0.1992, -0.0862,  0.0306,  0.1859,\n          0.1461, -0.2197, -0.0199,  0.1617,  0.1932, -0.0807,  0.1762, -0.1859,\n         -0.0856, -0.0830, -0.1693, -0.1126],\n        [ 0.0681, -0.0895, -0.2215, -0.1466,  0.0546,  0.0361, -0.1292,  0.0534,\n         -0.1325, -0.0982, -0.1453,  0.1195, -0.1106,  0.1341,  0.2214, -0.1976,\n          0.1085,  0.1599, -0.2066,  0.1416],\n        [ 0.0159, -0.0499,  0.2233,  0.1019, -0.2000, -0.1788, -0.2161, -0.1938,\n          0.1528, -0.0348, -0.0762, -0.1130,  0.1265, -0.0663,  0.1495, -0.0972,\n         -0.2118, -0.1028,  0.2030, -0.0514],\n        [-0.0292,  0.0349,  0.1394, -0.0171,  0.0122, -0.1425,  0.2156, -0.1874,\n          0.1282,  0.0847,  0.0640,  0.1520, -0.2036,  0.1646, -0.1682,  0.2001,\n         -0.0208, -0.1131, -0.0819,  0.0680],\n        [ 0.0634,  0.0517, -0.0931,  0.1145, -0.1828,  0.1778, -0.0790, -0.0385,\n          0.1467,  0.1975,  0.0867, -0.2150, -0.1249, -0.0173, -0.0734,  0.1063,\n         -0.0914,  0.1778,  0.1455, -0.0279],\n        [-0.2184, -0.1589, -0.0981,  0.0101, -0.0348,  0.0668,  0.0904, -0.0430,\n         -0.0624, -0.0266, -0.1163, -0.1724, -0.0078, -0.1821,  0.1035, -0.1708,\n         -0.0250,  0.0328,  0.0397,  0.0941],\n        [-0.0414,  0.0401,  0.0045,  0.1823,  0.1151, -0.1584,  0.1977, -0.0901,\n          0.0903,  0.1834,  0.1656,  0.0858,  0.1348,  0.2138,  0.0128,  0.1324,\n         -0.0315,  0.0253, -0.1935,  0.1775],\n        [ 0.0753,  0.0181,  0.1941,  0.0341, -0.0076,  0.1591,  0.0430,  0.0428,\n         -0.2192, -0.1320, -0.2166, -0.1050,  0.0177, -0.1303,  0.0510,  0.0656,\n          0.1901,  0.0057, -0.0615, -0.0537],\n        [ 0.1507,  0.2035, -0.1122, -0.0368,  0.0797,  0.1907,  0.1893,  0.0556,\n         -0.0828,  0.1093, -0.0905, -0.1294,  0.0201,  0.0274,  0.2024,  0.0610,\n         -0.1123,  0.0471,  0.2199, -0.0865],\n        [-0.0553,  0.1465, -0.1205, -0.0340,  0.1466, -0.1913, -0.1812,  0.2171,\n         -0.1596,  0.0356, -0.1335, -0.0007, -0.0697,  0.1559, -0.2180,  0.2112,\n          0.1261, -0.0095, -0.0097,  0.0021],\n        [-0.1768, -0.0998, -0.1805,  0.1209,  0.0264, -0.1709, -0.1951, -0.1642,\n         -0.1482,  0.0871, -0.0962,  0.2080,  0.1444, -0.0052, -0.0274, -0.1152,\n          0.1244,  0.0770,  0.1158,  0.1738],\n        [-0.1290,  0.0446,  0.0371,  0.1718, -0.1815, -0.1136,  0.0543, -0.1007,\n          0.0538, -0.0684, -0.1884,  0.0370, -0.1739,  0.1140,  0.0595,  0.0943,\n          0.1155,  0.1546, -0.1099, -0.1295],\n        [ 0.1957,  0.1246, -0.2153, -0.1457, -0.1782, -0.1529, -0.1325,  0.1462,\n          0.0241,  0.0275, -0.0895, -0.2010,  0.1452, -0.2219,  0.2015,  0.1182,\n          0.1714, -0.0531,  0.1124, -0.1103]])\nbias_ih_l0 tensor([ 0.1857,  0.2072,  0.2135,  0.0447, -0.0206,  0.1658, -0.0555, -0.0963,\n         0.0722,  0.1704, -0.0583,  0.1944, -0.0936,  0.1258, -0.1037,  0.0788,\n        -0.0101,  0.2041, -0.0009,  0.1743])\nbias_hh_l0 tensor([ 0.0521,  0.1074, -0.2097,  0.0076,  0.1477, -0.0535,  0.0359, -0.0309,\n        -0.1369,  0.1887, -0.0799,  0.0901, -0.1826, -0.0301,  0.0574, -0.1024,\n        -0.1988,  0.0921, -0.0252, -0.1512])\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "# 单向rnn\n",
    "# 定义输入数据\n",
    "input_size = 10   # 输入特征的维度\n",
    "sequence_length = 5   # 时间步个数\n",
    "batch_size = 3   # 批次大小\n",
    "\n",
    "# 创建随机输入数据\n",
    "#输入数据的维度为(sequence_length, batch_size, input_size)，表示有sequence_length个时间步，\n",
    "#每个时间步有batch_size个样本，每个样本的特征维度为input_size。\n",
    "input_data = torch.randn(sequence_length, batch_size, input_size)\n",
    "print(\"输入数据\",input_data)\n",
    "# 定义RNN模型\n",
    "# 定义RNN模型时，我们指定了输入特征的维度input_size、隐藏层的维度hidden_size、隐藏层的层数num_layers等参数。\n",
    "# batch_first=False表示输入数据的维度中批次大小是否在第一个维度，我们在第二个维度上。\n",
    "rnn = nn.RNN(input_size, hidden_size=20, num_layers=1, batch_first=False)\n",
    "\"\"\"\n",
    "在前向传播过程中，我们将输入数据传递给RNN模型，并得到输出张量output和最后一个时间步的隐藏状态hidden。\n",
    "输出张量的大小为(sequence_length, batch_size, hidden_size)，表示每个时间步的隐藏层输出。\n",
    "最后一个时间步的隐藏状态的大小为(num_layers, batch_size, hidden_size)。\n",
    "\"\"\"\n",
    "# 前向传播\n",
    "output, hidden = rnn(input_data)\n",
    "print(\"最后一个隐藏层\",hidden.shape)\n",
    "print(\"输出所有隐藏层\",output.shape)\n",
    "\n",
    "# 打印每个隐藏层的权重和偏置项\n",
    "# weight_ih表示输入到隐藏层的权重，weight_hh表示隐藏层到隐藏层的权重。\n",
    "# bias_ih表示输入到隐藏层的偏置，bias_hh表示隐藏层到隐藏层的偏置。\n",
    "for name, param in rnn.named_parameters():\n",
    "    if 'weight' in name or 'bias' in name:\n",
    "        print(name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "输出张量大小： torch.Size([5, 3, 40])\n最后一个时间步的隐藏状态大小： torch.Size([2, 3, 20])\ntensor([[[-5.7299e-01,  4.6317e-01,  3.7144e-01, -1.6791e-01, -5.9609e-01,\n          -1.6824e-01,  2.2061e-01,  7.7364e-03, -2.5497e-01,  7.6267e-02,\n          -1.2272e-01, -5.4451e-02,  3.1573e-01,  7.7138e-01, -4.9164e-02,\n           5.9472e-01, -3.8507e-01, -2.3786e-01,  1.0355e-01,  3.7581e-05,\n          -1.8062e-01, -3.6157e-01, -7.0713e-01, -1.5755e-01, -7.3579e-01,\n           2.5504e-01, -3.8225e-01,  1.2236e-01,  1.6387e-01, -7.9122e-01,\n          -1.9434e-01, -1.3199e-01, -5.1541e-01,  2.5086e-01, -1.9221e-01,\n          -6.3282e-01,  7.7050e-02, -2.5693e-01,  1.9461e-01,  2.3528e-01],\n         [ 8.0286e-01,  9.9603e-03,  6.7145e-02, -2.4458e-01,  1.6982e-02,\n           4.8949e-01, -3.6909e-01, -5.8071e-01,  6.6972e-01,  3.4980e-02,\n           1.4110e-01, -7.9643e-01,  5.3769e-01, -1.1732e-01, -4.1589e-01,\n          -1.5146e-01,  2.9248e-01, -4.6350e-01, -3.8934e-03, -7.1776e-01,\n          -2.0385e-01,  4.1999e-01,  1.8497e-01,  1.9864e-01,  1.7627e-01,\n          -1.6264e-01,  5.9412e-01,  4.1232e-01,  5.4836e-01, -1.8301e-01,\n          -7.5855e-01,  2.9494e-01, -5.5340e-01,  3.0398e-01,  9.2064e-01,\n           5.7635e-01,  4.0161e-01, -5.6926e-01,  1.5908e-01,  2.4843e-01],\n         [-4.8305e-01, -1.6200e-01, -5.1612e-02,  9.2438e-02,  2.8334e-01,\n           1.6126e-01, -6.2251e-01,  3.1781e-01, -5.7613e-01,  3.5436e-01,\n          -3.9412e-01,  3.4646e-01,  2.8742e-01, -1.1231e-01,  5.6042e-01,\n           8.9602e-02,  6.8386e-01, -1.7020e-01, -5.5703e-01, -5.3440e-02,\n           6.8487e-01, -4.4960e-01, -8.0486e-01,  1.3024e-01, -3.6882e-01,\n           6.5090e-01,  3.9811e-01, -3.7044e-01, -5.3825e-01,  8.1619e-03,\n          -5.0842e-01, -1.2489e-01, -7.5827e-01, -5.4997e-01, -4.3414e-01,\n          -6.0702e-02,  1.7283e-01, -4.9238e-01,  7.7452e-02,  4.7485e-01]],\n\n        [[ 4.2679e-02,  2.1883e-01,  1.9961e-01,  3.3949e-01, -2.0386e-01,\n          -5.3738e-01, -1.4879e-01,  2.4440e-01, -3.7862e-01, -4.2115e-02,\n           2.2847e-01, -9.3710e-02, -3.7413e-01,  4.3063e-01, -2.7360e-01,\n           4.7643e-01, -5.4454e-01, -2.5390e-01,  5.3171e-04,  1.9823e-01,\n           3.1138e-01,  1.5926e-01, -3.5399e-01,  9.4331e-02, -4.6343e-01,\n          -3.2079e-02,  5.6615e-02, -4.4643e-01,  6.2324e-01, -2.2281e-01,\n           1.6769e-01,  6.2723e-01, -5.0364e-01,  2.7861e-02,  2.8328e-01,\n          -4.0275e-01,  1.6933e-01,  1.8638e-02, -4.3291e-01,  5.0299e-01],\n         [-5.6819e-01,  7.6392e-01, -2.3890e-01,  1.1041e-01,  1.1791e-01,\n          -5.7162e-01,  1.3472e-01,  8.2764e-01, -5.5086e-01,  7.3796e-01,\n           5.9688e-02, -2.4929e-02, -4.8911e-01,  4.7911e-01, -1.1044e-01,\n           5.8115e-01, -1.2701e-01, -2.8183e-01, -6.0412e-02,  3.5783e-01,\n           6.1771e-01, -5.5324e-01, -8.9980e-01,  2.9812e-02, -7.3479e-01,\n           1.5284e-01,  2.2289e-01, -8.9889e-01, -1.8515e-01, -1.5108e-01,\n           2.4108e-02,  7.7846e-01, -5.3004e-01, -3.1445e-01, -5.2245e-01,\n          -8.8075e-01,  7.0426e-01,  1.0752e-01, -7.5873e-01,  6.2344e-01],\n         [-3.8493e-01, -5.8964e-02,  7.7059e-02, -1.9983e-01,  6.7783e-02,\n          -3.3249e-01,  8.9215e-01, -6.5327e-01, -1.6737e-01,  6.1240e-02,\n          -4.0659e-01, -5.5081e-01,  5.6137e-01,  5.3603e-01,  3.0374e-01,\n           5.0031e-01, -1.1008e-01,  9.7216e-02, -4.2169e-02,  1.8645e-01,\n          -3.3744e-01,  2.9062e-01,  4.6085e-02,  2.7510e-01, -5.0562e-01,\n          -7.8495e-01,  1.9302e-02,  4.6918e-01,  1.4709e-01, -4.4812e-01,\n          -2.0956e-01,  3.2580e-01, -1.2576e-01,  9.4663e-02, -5.1267e-01,\n           7.9851e-02, -1.7815e-01,  6.0617e-01,  5.8819e-02,  3.3354e-01]],\n\n        [[-5.8867e-01,  2.1151e-01,  5.9658e-01,  3.2707e-01, -5.3786e-01,\n          -5.1865e-01, -4.7302e-01,  8.9611e-02, -4.9486e-01,  5.6518e-01,\n          -3.6169e-01,  5.7706e-01,  4.8419e-01,  6.4882e-01,  9.2838e-02,\n           6.8141e-01, -6.2065e-01,  7.8587e-02, -1.0075e-01,  5.9842e-01,\n           2.5603e-01, -3.5043e-01, -6.5306e-01, -4.4305e-01, -9.0075e-01,\n           4.4278e-01,  1.0262e-01,  1.9593e-01, -1.9911e-01, -6.4322e-01,\n          -4.4308e-01, -3.6648e-01,  1.6772e-02,  7.6818e-01, -6.0566e-01,\n          -6.4354e-01,  5.3702e-01, -5.2610e-01, -3.2991e-01,  4.0311e-01],\n         [-3.0975e-01, -1.0469e-01,  7.0647e-01,  1.3285e-01, -5.4246e-01,\n          -8.0775e-02, -2.5971e-01, -2.7233e-01,  2.1577e-01, -4.2998e-01,\n          -1.1405e-01,  4.0065e-02,  6.0285e-02,  3.2272e-01,  1.8622e-01,\n          -1.8494e-01, -1.6598e-01,  1.4834e-01, -4.6372e-01,  6.1740e-01,\n           2.0172e-03,  6.1229e-02, -6.8527e-01,  1.7089e-01, -4.7716e-01,\n           3.6318e-01,  3.6305e-01,  2.2955e-01,  5.6847e-02, -7.5418e-01,\n          -2.4735e-01,  9.9958e-02, -4.7578e-01,  2.0570e-01,  3.4800e-01,\n          -4.6057e-01,  3.9189e-01, -5.6939e-01,  1.8497e-01,  5.5978e-01],\n         [-4.0902e-01,  1.2189e-01,  7.4800e-02, -4.8402e-02,  2.8988e-01,\n          -1.6171e-01,  3.0227e-01,  3.3886e-01, -5.8059e-01,  5.7668e-01,\n          -1.4432e-01,  2.2988e-01,  1.3124e-01,  7.3704e-01,  5.4477e-01,\n           5.1325e-01, -2.1225e-01, -1.0030e-01, -6.0867e-01,  5.3290e-02,\n           2.1782e-01,  2.7976e-01, -5.1620e-01, -2.6330e-01, -8.0401e-01,\n          -1.0502e-01,  5.4173e-01,  5.9571e-02, -1.4205e-01, -3.6164e-01,\n          -6.5500e-01,  4.6286e-01,  9.0868e-02,  5.5559e-01, -3.0084e-01,\n          -6.5650e-01,  3.1083e-01, -8.6392e-02, -7.5833e-01,  2.9991e-01]],\n\n        [[ 3.8893e-02, -5.1708e-01,  7.3399e-01, -5.3375e-01,  9.0499e-02,\n           2.9027e-01,  4.0522e-01, -7.8719e-01,  7.2401e-01, -4.4320e-01,\n          -4.9806e-02, -6.2982e-01, -1.0545e-01,  2.6376e-01, -3.3008e-01,\n           7.3892e-01,  2.3416e-01,  5.5079e-01, -1.0276e-01,  6.1950e-01,\n          -7.6883e-01,  1.8614e-01,  4.3976e-01,  6.0885e-01,  4.7763e-01,\n          -3.6694e-01,  8.2084e-02, -2.7496e-01,  9.1539e-01,  2.4914e-01,\n           2.3953e-01,  2.4344e-01, -8.4291e-01, -1.3465e-01,  7.7440e-01,\n           4.4983e-01,  7.1984e-01, -9.6631e-02,  8.1889e-01,  6.8907e-01],\n         [-8.3231e-02, -2.5144e-01, -3.4263e-02,  7.9535e-02, -2.8578e-01,\n          -1.8564e-01,  1.4193e-01,  3.4984e-01,  1.6294e-01,  7.4659e-01,\n          -5.3266e-01, -3.4784e-01, -6.2511e-01, -4.9668e-01,  1.6275e-01,\n           2.9470e-01, -1.9692e-02, -3.3715e-01, -2.3784e-01,  6.1678e-01,\n          -8.4779e-03,  4.5227e-01,  3.5922e-01,  2.1486e-01, -2.9842e-01,\n          -1.4750e-01,  4.9016e-01, -1.9045e-02,  6.7306e-01,  3.1806e-01,\n          -2.8938e-01,  1.0974e-01, -4.6675e-01,  7.8568e-01,  1.1016e-01,\n          -4.9941e-01,  5.8916e-01,  2.7526e-01, -2.2204e-01,  7.0611e-01],\n         [ 2.6503e-01, -2.3659e-01,  8.2934e-01,  1.3413e-01, -2.8306e-01,\n          -1.3254e-01, -4.0553e-01, -1.2306e-01, -4.4162e-02,  5.0229e-01,\n          -4.0124e-01, -2.0335e-01,  1.2844e-01,  4.5051e-01,  1.2697e-03,\n           3.0027e-01, -1.8770e-01, -4.5251e-01, -5.1689e-01,  2.9250e-01,\n           2.5367e-01,  2.7681e-01,  6.9382e-02, -1.8243e-01, -5.5639e-01,\n           4.5553e-01,  4.1356e-01, -1.6678e-01,  5.5471e-01, -3.5997e-02,\n          -5.5760e-01, -7.3955e-02, -7.4833e-01,  4.9220e-01,  2.7172e-01,\n          -3.0662e-01,  4.6691e-01, -3.5329e-01, -2.0514e-01,  6.9967e-01]],\n\n        [[-5.4176e-01,  8.1464e-01, -8.7065e-01, -5.9640e-01, -2.7283e-01,\n           7.7027e-01,  6.3050e-01,  4.3491e-01,  1.5239e-01,  3.8383e-01,\n          -7.3957e-01,  1.2241e-01, -1.5348e-01,  2.3774e-02,  4.0546e-01,\n          -5.7691e-01, -5.1418e-01, -3.1620e-01,  4.7513e-01, -4.5697e-01,\n           5.9922e-01,  4.6395e-01, -2.0084e-01,  2.7092e-02, -2.7748e-01,\n           9.0246e-02,  1.9348e-01,  4.6965e-01,  5.4811e-01, -1.1596e-01,\n          -1.2616e-01, -5.6451e-01,  2.8411e-01,  3.2466e-01, -5.3828e-01,\n          -3.2854e-01, -6.0000e-01, -4.0193e-01,  4.2420e-01, -2.8628e-01],\n         [-3.5676e-01,  6.2509e-01,  3.3934e-01,  8.4828e-02, -7.2327e-01,\n          -1.4524e-01, -6.3449e-01,  2.4566e-01,  8.7060e-02, -1.0029e-01,\n          -3.5755e-02, -2.3880e-01,  3.9092e-01,  3.1712e-01, -1.8514e-01,\n           3.7819e-01, -9.1759e-02,  2.5947e-02, -1.2639e-01,  1.7041e-02,\n           3.8095e-01,  1.0692e-01, -3.7395e-01, -6.8033e-02, -5.6622e-01,\n           6.5430e-01,  2.4105e-01,  4.9832e-02,  1.0019e-01, -2.2197e-01,\n          -6.3179e-01, -1.2854e-01, -4.0040e-01,  7.1143e-02,  1.4270e-01,\n          -2.3192e-01,  3.9442e-01, -3.7705e-01,  2.9209e-02,  4.9681e-01],\n         [-4.5234e-01,  2.0026e-01,  5.1561e-01,  2.3087e-01,  2.9743e-01,\n          -3.3966e-01,  1.1755e-01, -2.3374e-01, -5.3221e-01,  5.3717e-01,\n          -7.5743e-01,  3.9311e-01,  9.0199e-02,  7.2721e-01, -1.5685e-01,\n           6.1857e-01,  1.8399e-02, -2.6127e-01,  3.6476e-01,  5.7249e-01,\n          -1.4202e-02, -4.8684e-01, -7.0038e-01, -1.8449e-01, -4.8763e-01,\n          -4.5981e-02, -3.5026e-01, -2.4884e-01, -2.6032e-01, -2.7099e-01,\n           7.1302e-02,  1.9963e-01, -6.5566e-01,  1.2859e-01, -2.7258e-01,\n          -1.7068e-01,  2.4055e-01, -2.5919e-01,  2.4884e-01,  1.8734e-01]]],\n       grad_fn=<CatBackward0>)\ntensor([[[-0.5418,  0.8146, -0.8707, -0.5964, -0.2728,  0.7703,  0.6305,\n           0.4349,  0.1524,  0.3838, -0.7396,  0.1224, -0.1535,  0.0238,\n           0.4055, -0.5769, -0.5142, -0.3162,  0.4751, -0.4570],\n         [-0.3568,  0.6251,  0.3393,  0.0848, -0.7233, -0.1452, -0.6345,\n           0.2457,  0.0871, -0.1003, -0.0358, -0.2388,  0.3909,  0.3171,\n          -0.1851,  0.3782, -0.0918,  0.0259, -0.1264,  0.0170],\n         [-0.4523,  0.2003,  0.5156,  0.2309,  0.2974, -0.3397,  0.1176,\n          -0.2337, -0.5322,  0.5372, -0.7574,  0.3931,  0.0902,  0.7272,\n          -0.1569,  0.6186,  0.0184, -0.2613,  0.3648,  0.5725]],\n\n        [[-0.1806, -0.3616, -0.7071, -0.1576, -0.7358,  0.2550, -0.3823,\n           0.1224,  0.1639, -0.7912, -0.1943, -0.1320, -0.5154,  0.2509,\n          -0.1922, -0.6328,  0.0771, -0.2569,  0.1946,  0.2353],\n         [-0.2039,  0.4200,  0.1850,  0.1986,  0.1763, -0.1626,  0.5941,\n           0.4123,  0.5484, -0.1830, -0.7586,  0.2949, -0.5534,  0.3040,\n           0.9206,  0.5764,  0.4016, -0.5693,  0.1591,  0.2484],\n         [ 0.6849, -0.4496, -0.8049,  0.1302, -0.3688,  0.6509,  0.3981,\n          -0.3704, -0.5382,  0.0082, -0.5084, -0.1249, -0.7583, -0.5500,\n          -0.4341, -0.0607,  0.1728, -0.4924,  0.0775,  0.4748]]],\n       grad_fn=<StackBackward0>)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "#双向rnn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 定义输入数据\n",
    "input_size = 10   # 输入特征的维度\n",
    "sequence_length = 5   # 时间步个数\n",
    "batch_size = 3   # 批次大小\n",
    "\n",
    "# 创建随机输入数据\n",
    "input_data = torch.randn(sequence_length, batch_size, input_size)\n",
    "\n",
    "# 定义双向RNN模型\n",
    "rnn = nn.RNN(input_size, hidden_size=20, num_layers=1, batch_first=False, bidirectional=True)\n",
    "\n",
    "# 前向传播\n",
    "output, hidden = rnn(input_data)\n",
    "\n",
    "# 输出结果\n",
    "print(\"输出张量大小：\", output.size())\n",
    "print(\"最后一个时间步的隐藏状态大小：\", hidden.size())\n",
    "print(output)\n",
    "print(hidden)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Output shape: torch.Size([4, 3, 10])\nHidden state shape: torch.Size([2, 3, 10])\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "#多层rnn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 定义输入数据和参数\n",
    "input_size = 5\n",
    "hidden_size = 10\n",
    "num_layers = 2\n",
    "batch_size = 3\n",
    "sequence_length = 4\n",
    "\n",
    "# 创建输入张量\n",
    "input_tensor = torch.randn(sequence_length, batch_size, input_size)\n",
    "\n",
    "# 创建多层RNN模型\n",
    "rnn = nn.RNN(input_size, hidden_size, num_layers)\n",
    "\n",
    "# 前向传播\n",
    "output, hidden = rnn(input_tensor)\n",
    "\n",
    "# 打印输出张量和隐藏状态的大小\n",
    "print(\"Output shape:\", output.shape)\n",
    "print(\"Hidden state shape:\", hidden.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}