{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tensor([[0.3054, 0.9912, 0.2146],\n        [0.1266, 0.2386, 0.8449],\n        [0.7133, 0.0423, 0.9200],\n        [0.6459, 0.8170, 0.5100],\n        [0.4447, 0.8485, 0.7684]])\ntensor([[0.5207, 0.9808, 0.8766],\n        [0.3401, 0.9066, 0.3276],\n        [0.5948, 0.7213, 0.9866],\n        [0.7218, 0.2983, 0.3878],\n        [0.8546, 0.7904, 0.6089]])\ntorch.Size([5, 3])\ntensor([[0.8310, 1.1883, 1.6212],\n        [0.7104, 1.6271, 0.4547],\n        [0.8926, 1.5919, 1.9287],\n        [0.7887, 0.8406, 1.2543],\n        [0.9733, 1.0265, 0.7062]])\n[1. 1. 1. 1. 1.]\ntensor([2, 2, 2], dtype=torch.int32)\n[[1 2]\n [5 4]]\ntensor([[1, 2],\n        [5, 4]], dtype=torch.int32)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import torch as t\n",
    "import numpy as np\n",
    "#构建5*3数组,只是分配了空间未初始化\n",
    "result=t.Tensor(5,3)\n",
    "print(result)\n",
    "#这里产生个0-1之间的tensor张量，并且初始化\n",
    "x1=t.rand(5,3)\n",
    "y1=t.rand(5,3)\n",
    "print(x1)\n",
    "print(x1.size())\n",
    "result=x1+y1\n",
    "print(result)\n",
    "#产生5个1的一维数组tensor转换成numpy\n",
    "print(t.ones(5).numpy())\n",
    "#将numpy数组转换为tensor\n",
    "print(t.from_numpy(np.array([2,2,2,])))\n",
    "\"\"\"\n",
    "Tensor和numpy对象共享内存，所以它们之间的转换很快，而且几乎不会消耗资源。这也意味着，如果其中一个变了，另外一个也会随之改变\n",
    "\"\"\"\n",
    "npArray=np.array([[1,2],[3,4]])\n",
    "npTensor=t.from_numpy(npArray)\n",
    "npArray[1][0]=5\n",
    "print(npArray)\n",
    "print(npTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tensor([ 0.3721,  0.0868, -0.4250, -1.9881,  0.5537, -1.9975,  0.6286,  0.2254])\ntensor([[0, 4],\n        [3, 7]])\ntensor([[ 0.6611, -0.2953,  0.8079],\n        [-0.0476,  1.7553, -0.2959]])\ntensor([0, 2, 4, 6, 8])\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "#常用来产生随机数,torch.randn()：生成8个满足标准正态分布（均值为0，方差为1）的随机数。\n",
    "print(t.randn(8))\n",
    "# 生成一个在范围[0, 10)内的整数随机数\n",
    "print(t.randint(0,10,(2,2)))\n",
    "#生成一个形状为2x3的张量，其中的元素是从均值为0，标准差为1的正态分布中随机抽取的数值。\n",
    "random_tensor = t.normal(0, 1, size=(2, 3))\n",
    "print(random_tensor)\n",
    "\n",
    "#这将生成一个包含从0开始的、步长为2的等差数列，直到小于10为止的张量。\n",
    "sequence = t.arange(0, 10, 2)\n",
    "print(sequence)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "torch.Size([3, 5])\ntorch.Size([1, 3, 5])\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "#常用的函数汇总 squeeze:去除维度为1\n",
    "x = t.randn(1, 3, 1, 5)  # 输入张量的维度为 [1, 3, 1, 5]\n",
    "y = t.squeeze(x)  # 去除维度为1的维度\n",
    "print(y.size())  # 输出：torch.Size([3, 5])\n",
    "z = t.squeeze(x, dim=2)  # 仅去除第二个维度的维度为1的维度\n",
    "print(z.size())  # 输出：torch.Size([1, 3, 5])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tensor([[19, 22],\n        [43, 50]])\ndot_result_ab:\n [[19 22]\n [43 50]]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# mm函数矩阵点乘\n",
    "import numpy as np\n",
    "x = t.tensor([[1, 2], [3, 4]]) # 左操作数，2x2的矩阵\n",
    "y = t.tensor([[5, 6], [7, 8]]) # 右操作数，2x2的矩阵\n",
    "\n",
    "z = t.mm(x, y) # 矩阵乘法\n",
    "print(z)\n",
    "\n",
    "result_ab = np.dot(x, y)\n",
    "print('dot_result_ab:\\n %s' %(result_ab))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "原始张量 x:\n tensor([[1, 2],\n        [3, 4]])\n目标张量 y:\n tensor([[0, 0],\n        [0, 0]])\n通过 expand_as() 扩展的张量 expanded_x:\n tensor([[1, 2],\n        [3, 4]])\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "#PyTorch中的expand_as()是一个张量方法，用于将一个张量扩展为与另一个张量具有相同大小的形状。这意味着它通过复制原始张量的值来填充新的张量，使其具有与目标张量相同的形状。\n",
    "import torch\n",
    "\n",
    "# 创建原始张量\n",
    "x = torch.tensor([[1, 2],\n",
    "                  [3, 4]])\n",
    "# 创建目标张量\n",
    "y = torch.tensor([[0, 0],\n",
    "                  [0, 0]])\n",
    "# 使用expand_as()扩展原始张量为目标张量的形状\n",
    "expanded_x = x.expand_as(y)\n",
    "print(\"原始张量 x:\\n\", x)\n",
    "print(\"目标张量 y:\\n\", y)\n",
    "print(\"通过 expand_as() 扩展的张量 expanded_x:\\n\", expanded_x)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\n常用的数学函数\\n'"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 52
    }
   ],
   "source": [
    "\"\"\"\n",
    "常用的数学函数\n",
    "当然，下面是PyTorch中一些常用的数学函数的清单，每个都附有简短的描述和一个调用小例子：\n",
    "    torch.abs(input): 返回输入张量的绝对值。示例：torch.abs(torch.tensor([-1, 2, -3]))。\n",
    "    torch.sqrt(input): 返回输入张量的平方根。示例：torch.sqrt(torch.tensor([4, 9, 16]))。\n",
    "    torch.exp(input): 计算输入张量的指数函数。示例：torch.exp(torch.tensor([1, 2, 3]))。\n",
    "    torch.log(input): 计算输入张量的自然对数。示例：torch.log(torch.tensor([1, 10, 100]))。\n",
    "    torch.sin(input): 计算输入张量的正弦值。示例：torch.sin(torch.tensor([0, math.pi/2, math.pi]))。\n",
    "    torch.cos(input): 计算输入张量的余弦值。示例：torch.cos(torch.tensor([0, math.pi/2, math.pi]))。\n",
    "    torch.tan(input): 计算输入张量的正切值。示例：torch.tan(torch.tensor([0, math.pi/4, math.pi/2]))。\n",
    "    torch.sigmoid(input): 计算输入张量的Sigmoid函数。示例：torch.sigmoid(torch.tensor([0, 1, 2]))。\n",
    "    torch.relu(input): 应用ReLU激活函数，即max(0, input)。示例：torch.relu(torch.tensor([-1, 0, 1]))。\n",
    "    torch.softmax(input, dim): 计算输入张量在指定维度上的Softmax函数。示例：torch.softmax(torch.tensor([[1, 2], [3, 4]]), dim=1)。\n",
    "    torch.mean(input): 计算输入张量的均值。示例：torch.mean(torch.tensor([1, 2, 3]))。\n",
    "    torch.sum(input): 计算输入张量的总和。示例：torch.sum(torch.tensor([1, 2, 3]))。\n",
    "    torch.max(input): 返回输入张量中的最大值。示例：torch.max(torch.tensor([1, 2, 3]))。\n",
    "    torch.min(input): 返回输入张量中的最小值。示例：torch.min(torch.tensor([1, 2, 3]))。\n",
    "    torch.argmax(input): 返回输入张量中最大值的索引。示例：torch.argmax(torch.tensor([1, 2, 3]))。\n",
    "    torch.argmin(input): 返回输入张量中最小值的索引。示例：torch.argmin(torch.tensor([1, 2, 3]))。\n",
    "    torch.sort(input): 对输入张量进行排序。示例：torch.sort(torch.tensor([3, 1, 2]))。\n",
    "    torch.clamp(input, min, max): 将输入张量的值限制在指定范围内。示例：torch.clamp(torch.tensor([1, 2, 3]), min=2, max=3)。\n",
    "    torch.round(input): 对输入张量进行四舍五入。示例：torch.round(torch.tensor([1.1, 2.4, 3.6]))。\n",
    "    torch.floor(input): 向下取整，返回不大于输入张量的最大整数。示例：torch.floor(torch.tensor([1.1, 2.4, 3.6]))。\n",
    "常用矩阵处理函数\n",
    "以下是PyTorch中常用的20个矩阵处理函数的清单及其描述：\n",
    "    torch.mm(): 计算两个矩阵的乘积。\n",
    "    示例：torch.mm(torch.tensor([[1, 2], [3, 4]]), torch.tensor([[5], [6]]))返回tensor([[17], [39]])\n",
    "    \n",
    "    torch.matmul(): 计算两个张量的矩阵乘积。\n",
    "    示例：torch.matmul(torch.tensor([[1, 2], [3, 4]]), torch.tensor([[5], [6]]))返回tensor([[17], [39]])\n",
    "    \n",
    "    torch.transpose(): 返回输入张量的转置。\n",
    "    示例：torch.transpose(torch.tensor([[1, 2], [3, 4]]), 0, 1)返回tensor([[1, 3], [2, 4]])\n",
    "    \n",
    "    torch.mm(): 计算一个矩阵和一个向量的乘积。\n",
    "    示例：torch.mm(torch.tensor([[1, 2], [3, 4]]), torch.tensor([5, 6]))返回tensor([17, 39])\n",
    "    \n",
    "    torch.trace(): 返回矩阵的迹。\n",
    "    示例：torch.trace(torch.tensor([[1, 2], [3, 4]]))返回tensor(5)\n",
    "    \n",
    "    torch.det(): 计算矩阵的行列式。\n",
    "    示例：torch.det(torch.tensor([[1, 2], [3, 4]]))返回tensor(-2)\n",
    "    \n",
    "    torch.svd(): 对矩阵进行奇异值分解。\n",
    "    示例：torch.svd(torch.tensor([[1, 2], [3, 4]]))返回(tensor([[-0.4046, -0.9145], [-0.9145, 0.4046]]), tensor([5.4645, 0.3650]), tensor([[-0.5760, -0.8174], [-0.8174, 0.5760]]))\n",
    "    \n",
    "    torch.eig(): 计算矩阵的特征值和特征向量。\n",
    "    示例：torch.eig(torch.tensor([[1, 2], [3, 4]]))返回(tensor([[0.3723, 0.0000], [5.6277, 0.0000]]), tensor([]))\n",
    "    \n",
    "    torch.inverse(): 计算矩阵的逆。\n",
    "    示例：torch.inverse(torch.tensor([[1, 2], [3, 4]]))返回tensor([[-2.0000, 1.0000], [ 1.5000, -0.5000]])\n",
    "    \n",
    "    torch.diag(): 返回矩阵的对角线元素。\n",
    "    示例：torch.diag(torch.tensor([[1, 2], [3, 4]]))返回tensor([1, 4])\n",
    "    \n",
    "    torch.diag_embed(): 将一维张量转化为对角矩阵。\n",
    "    示例：torch.diag_embed(torch.tensor([1, 2, 3]))返回tensor([[[1, 0, 0], [0, 0, 0], [0, 0, 0]], [[0, 0, 0], [0, 2, 0], [0, 0, 0]], [[0, 0, 0], [0, 0, 0], [0, 0, 3]]])\n",
    "    \n",
    "    torch.einsum(): 执行爱因斯坦求和约定。\n",
    "    示例：torch.einsum('ij,jk->ik', torch.tensor([[1, 2], [3, 4]]), torch.tensor([[5, 6], [7, 8]]))返回tensor([[19, 22], [43, 50]])\n",
    "    \n",
    "    torch.flatten(): 对输入张量进行扁平化操作。\n",
    "    示例：torch.flatten(torch.tensor([[1, 2], [3, 4]]))返回tensor([1, 2, 3, 4])\n",
    "    \n",
    "    torch.cat(): 沿指定维度拼接张量。\n",
    "    示例：torch.cat((torch.tensor([[1, 2]]), torch.tensor([[3, 4]])), dim=0)返回tensor([[1, 2], [3, 4]])\n",
    "    \n",
    "    torch.stack(): 沿新维度拼接张量。\n",
    "    示例：torch.stack((torch.tensor([1, 2]), torch.tensor([3, 4])), dim=0)返回tensor([[1, 2], [3, 4]])\n",
    "    \n",
    "    torch.split(): 沿指定维度分割张量。\n",
    "    示例：torch.split(torch.tensor([[1, 2, 3, 4]]), 2, dim=1)返回(tensor([[1, 2]]), tensor([[3, 4]]))\n",
    "    \n",
    "    torch.chunk(): 将张量分割成指定数量的块。\n",
    "    示例：torch.chunk(torch.tensor([[1, 2, 3, 4]]), 2, dim=1)返回(tensor([[1, 2]]), tensor([[3, 4]]))\n",
    "    \n",
    "    torch.reshape(): 改变张量的形状。\n",
    "    示例：torch.reshape(torch.tensor([[1, 2, 3, 4]]), (2, 2))返回tensor([[1, 2], [3, 4]])\n",
    "    \n",
    "    torch.squeeze(): 压缩张量中尺寸为1的维度。\n",
    "    示例：torch.squeeze(torch.tensor([[[1], [2]]]))返回tensor([1, 2])\n",
    "    \n",
    "    torch.unsqueeze(): 在指定位置插入尺寸为1的新维度。\n",
    "    示例：torch.unsqueeze(torch.tensor([1, 2]), dim=1)返回tensor([[1], [2]]\n",
    "    \n",
    "    torch.view是PyTorch中的一个函数，用于改变张量的形状，即对张量进行重塑操作。它的作用类似于NumPy中的reshape函数。\n",
    "    # 创建一个张量\n",
    "    x = torch.tensor([1, 2, 3, 4, 5, 6])\n",
    "    y = x.view(2, 3)\n",
    "\n",
    "    permute函数是PyTorch中的一个函数，用于重新排列张量的维度顺序。它的作用是交换或重新组织张量的维度。\n",
    "        import torch\n",
    "        x = torch.randn(2, 3, 4)  # 创建一个形状为(2, 3, 4)的张量\n",
    "        x_permuted = x.permute(2, 0, 1)  # 将维度顺序重新排列为(4, 2, 3)\n",
    "        print(x_permuted.shape)  # 输出: torch.Size([4, 2, 3])\n",
    "        在上述示例中，原始张量x的维度顺序为(2, 3, 4)，通过使用permute(2, 0, 1)，将维度顺序重新排列为(4, 2, 3)，得到了新的张量x_permuted。\n",
    "        也就是维度2换成函数索引0个维度,0维度的换成1,1维度的换成2\n",
    "    torch.full函数是PyTorch中的一个函数，用于创建一个指定形状的张量，并用指定的数值填充。\n",
    "        函数的语法如下：\n",
    "        torch.full(size, fill_value, dtype=None, layout=torch.strided, device=None, requires_grad=False) -> Tensor\n",
    "        \n",
    "        参数说明：\n",
    "        size：张量的形状，可以是一个整数，也可以是一个元组或列表。\n",
    "        fill_value：要用于填充张量的数值。\n",
    "        dtype（可选）：指定张量的数据类型，默认为None，即使用默认的数据类型。\n",
    "        layout（可选）：指定张量的布局，默认为torch.strided。\n",
    "        device（可选）：指定张量所在的设备，默认为None，即使用默认设备。\n",
    "        requires_grad（可选）：指定张量是否需要计算梯度，默认为False。\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}